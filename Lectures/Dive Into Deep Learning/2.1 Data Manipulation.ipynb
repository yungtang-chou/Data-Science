{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1388f18",
   "metadata": {},
   "source": [
    "# 2.1 Data Manipulation\n",
    "\n",
    "## Table of Contents\n",
    "[2.1.1 Getting Started](#start)\n",
    "\n",
    "[2.1.2 Operations](#operation)\n",
    "\n",
    "[2.1.3 Broadcasting Mechanism](#broad)\n",
    "\n",
    "[2.1.4 Indexing and Slicing](#index)\n",
    "\n",
    "[2.1.5 Saving Memory](#mem)\n",
    "\n",
    "[2.1.6 Conversion to Other Python Objects](#conv)\n",
    "\n",
    "[2.1.7 Summary](#sum)\n",
    "\n",
    "[2.1.8 Exercises](#ex)\n",
    "\n",
    "\n",
    "## 2.1.1 Getting Started <a name=\"start\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6277d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Pytorch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c609fe3",
   "metadata": {},
   "source": [
    "A tensor represents a (possibly multi-dimensional) array of numerical values. With one axis, a tensor corresponds (in math) to a *vector*. With two axes, a tensor corresponds to a *matrix*.\n",
    "\n",
    "Each of the values in a tensor is called an **element of the tensor**. Unless otherwise specified, a new tensor will be stored in main memory and designated for **CPU-based computation**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b7fd68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct synthetic tensor\n",
    "x = torch.arange(12)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41278ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the tensor shape\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1224527c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the total number of elements in a tensor\n",
    "x.numel() # num of elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd41dfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "\n",
      "\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "# Reshape the tensor without altering the value and number of the elements\n",
    "X = x.reshape(3,4)\n",
    "print(X)\n",
    "print('\\n')\n",
    "\n",
    "# Manually specifying multiple dimensions are not necessary. We can specify -1 and pytorch will invoke the corresponding value\n",
    "X_ = x.reshape(3, -1)\n",
    "print(X_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba817bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor with all elements set to 0\n",
    "torch.zeros((2,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68ede659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor with all elemnets set to 1\n",
    "torch.ones((2,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f504bd9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.4676, -1.2175, -0.3053, -0.1694],\n",
       "        [-0.7237,  0.0891,  0.4163,  0.9658],\n",
       "        [-1.1075,  0.2956, -0.0222,  0.5034]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor with reandomly sampled values\n",
    "torch.randn(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fc02728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 1, 4, 3],\n",
       "        [1, 2, 3, 4],\n",
       "        [4, 3, 2, 1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the values of each element by providing python list\n",
    "torch.tensor([[2,1,4,3],\n",
    "            [1,2,3,4],\n",
    "            [4,3,2,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf28710",
   "metadata": {},
   "source": [
    "## 2.1.2 Operations <a name=\"operation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9cb64ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3.,  4.,  6., 10.])\n",
      "tensor([-1.,  0.,  2.,  6.])\n",
      "tensor([ 2.,  4.,  8., 16.])\n",
      "tensor([0.5000, 1.0000, 2.0000, 4.0000])\n",
      "tensor([ 1.,  4., 16., 64.])\n"
     ]
    }
   ],
   "source": [
    "# Arithmetic operations have all been lifted to elementwise operations\n",
    "x = torch.tensor([1.0, 2, 4, 8])\n",
    "y = torch.tensor([2, 2, 2, 2])\n",
    "print(x + y)\n",
    "print(x - y)\n",
    "print(x * y)\n",
    "print(x / y)\n",
    "print(x ** y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97654aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7183e+00, 7.3891e+00, 5.4598e+01, 2.9810e+03])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exponentiation is also applied elementwise\n",
    "torch.exp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab21e11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [ 2.,  1.,  4.,  3.],\n",
      "        [ 1.,  2.,  3.,  4.],\n",
      "        [ 4.,  3.,  2.,  1.]])\n",
      "\n",
      "\n",
      "tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n",
      "        [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor concatenation\n",
    "X = torch.arange(12, dtype = torch.float32).reshape((3,4))\n",
    "Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "print(torch.cat((X, Y), dim=0))\n",
    "print('\\n')\n",
    "print(torch.cat((X, Y), dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50c80183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True, False,  True],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logical Operatior also apply elementwise\n",
    "X == Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7235b9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(66.)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summing up all the elements\n",
    "X.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916734c8",
   "metadata": {},
   "source": [
    "## 2.1.3 Broadcasting Mechanism <a name=\"broad\"></a>\n",
    "\n",
    "Under certain conditions, even when shapes differ, we can still perform elementwise operations by invoking the broadcasting mechanism. \n",
    "\n",
    "1. Expand one or both arrays by copying elements appropriately so that after this transformation, the two tensors have the same shape.\n",
    "\n",
    "2. Carry out the elementwise operations on the resulting arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53bf8fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [1],\n",
       "         [2]]),\n",
       " tensor([[0, 1]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up example\n",
    "a = torch.arange(3).reshape((3,1))\n",
    "b = torch.arange(2).reshape((1,2))\n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a39ea03",
   "metadata": {},
   "source": [
    "Although a and b are of different shape, We broadcast the entries of both matrices into a larger  $3√ó2$  matrix as follows: for matrix $a$ it **replicates the columns and for matrix $b$ it replicates the rows before adding up both elementwise**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43d95a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 2],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469d5f50",
   "metadata": {},
   "source": [
    "## 2.1.4 Indexing and Slicing <a name=\"index\"></a>\n",
    "\n",
    "Similar to Python array, elements in a tensor can be accessed by index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa61669f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1dd2bc24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8.,  9., 10., 11.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9cc83137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4e2a5e",
   "metadata": {},
   "source": [
    "Beyond reading, we can also write elements of a matrix by specifying indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18210124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  9.,  7.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write single value\n",
    "X[1, 2] = 9\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d247d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12., 12., 12., 12.],\n",
       "        [12., 12., 12., 12.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write multiple values at the same time\n",
    "X[0:2, :] = 12\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9343264",
   "metadata": {},
   "source": [
    "## 2.1.5 Saving Memory  <a name=\"mem\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95704610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = id(Y)\n",
    "Y = Y + X\n",
    "id(Y) == before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135bf899",
   "metadata": {},
   "source": [
    "After running $Y = Y + X$, we will find that **id(Y)** points to a different location. That is because Python **first evaluates $Y + X$**, allocating new memory for the result, and then **makes Y point to this new location in memory**.\n",
    "\n",
    "This might be undesirable for two reasons.\n",
    "1. We do not want to allocate unnecessary memory usage. Typically, we want to perform these updates **in place**.\n",
    "2. If we do not update in place, some references might point to the old reference, making part of the code to break. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "daf65ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id(Z): 140296723607296\n",
      "id(Z): 140296723607296\n"
     ]
    }
   ],
   "source": [
    "Z = torch.zeros_like(Y) ## Returns a tensor filled with `0`, with the same size as the input\n",
    "print('id(Z):', id(Z))\n",
    "Z[:] = X + Y\n",
    "print('id(Z):', id(Z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb579f85",
   "metadata": {},
   "source": [
    "## 2.1.6 Conversion to Other Python Objects  <a name=\"conv\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "66c8e430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, torch.Tensor)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting numpy to tensor and vice versa\n",
    "A = X.numpy() ## convert to numpy\n",
    "B = torch.tensor(A) ## convert back to tensor\n",
    "\n",
    "type(A), type(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e628f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3.5000]), 3.5, 3.5, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert size-1 tensor to a python scalar\n",
    "a = torch.tensor([3.5])\n",
    "a, a.item(), float(a), int(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33a8376",
   "metadata": {},
   "source": [
    "## 2.1.7 Summary <a name=\"sum\"></a>\n",
    "\n",
    "* The main interface to store and manipulate data for deep learning is the tensor ( ùëõ -dimensional array). It provides a variety of functionalities including basic mathematics operations, broadcasting, indexing, slicing, memory saving, and conversion to other Python objects.\n",
    "\n",
    "## 2.1.8 Exercises <a name=\"ex\"></a>\n",
    "\n",
    "1. Run the code in this section. Change the conditional statement X == Y in this section to X < Y or X > Y, and then see what kind of tensor you can get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "49c61294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[False, False, False, False],\n",
       "         [ True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True]]),\n",
       " tensor([[ True, False,  True, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False]]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor concatenation\n",
    "X = torch.arange(12, dtype = torch.float32).reshape((3,4))\n",
    "Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "\n",
    "## X > Y and X < Y are still elementwise\n",
    "X > Y, X < Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5932a15c",
   "metadata": {},
   "source": [
    "2. Replace the two tensors that operate by element in the broadcasting mechanism with other shapes, e.g., 3-dimensional tensors. Is the result the same as expected?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f6c9735f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1],\n",
       "         [2, 3],\n",
       "         [4, 5]]),\n",
       " tensor([[0, 1]]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(6).reshape((3,2))\n",
    "b = torch.arange(2).reshape((1,2))\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e5c65d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2],\n",
       "        [2, 4],\n",
       "        [4, 6]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Broadcast happens as expected\n",
    "a + b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
